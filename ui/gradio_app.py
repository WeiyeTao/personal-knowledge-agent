import gradio as gr
from pathlib import Path
from tools.note_manager import add_note

from tools.file_loader import load_files
from tools.embedder import get_embeddings
from tools.retriever import build_vector_store, query
from openai import OpenAI

# === åˆå§‹åŒ– ===
client = OpenAI()
DATA_DIR = Path("data/notes")
DATA_DIR.mkdir(parents=True, exist_ok=True)

# === æ„å»ºå‘é‡æ•°æ®åº“ï¼ˆåˆå§‹åŒ–ä¸€æ¬¡ï¼‰ ===
def build_collection():
    docs = load_files([str(DATA_DIR)])
    texts = [d["content"] for d in docs]
    if not texts:
        return None
    embeddings = get_embeddings(texts)
    collection = build_vector_store(texts, embeddings)
    return collection

collection = build_collection()


# === å›è°ƒå‡½æ•° 1ï¼šæ–°å¢ç¬”è®° ===
def process_note(note_text):
    if not note_text.strip():
        return "âš ï¸ è¯·è¾“å…¥å†…å®¹ï¼"
    try:
        category, note_path = add_note(note_text)
        return f"âœ… åˆ†ç±»ï¼š**{category}**\nğŸ“„ å·²ä¿å­˜åˆ°ï¼š`{note_path.resolve()}`"
    except Exception as e:
        return f"âŒ å‡ºé”™å•¦ï¼š{str(e)}"


# === å›è°ƒå‡½æ•° 2ï¼šæŸ¥çœ‹å†å²ç¬”è®° ===
def show_notes():
    files = sorted(Path(DATA_DIR).rglob("*.md"))
    if not files:
        return "ğŸ“­ æš‚æ— ç¬”è®°ï¼Œè¯·å…ˆæ·»åŠ å†…å®¹ã€‚"

    md_text = "## ğŸ“š å†å²ç¬”è®°åˆ—è¡¨\n"
    for f in files:
        md_text += f"- `{f}`\n"
    return md_text


# === å›è°ƒå‡½æ•° 3ï¼šè‡ªç„¶è¯­è¨€æ£€ç´¢åˆ†æ ===
def query_notes(query_text):
    if not query_text.strip():
        return "âš ï¸ è¯·è¾“å…¥æŸ¥è¯¢å†…å®¹ï¼"

    # ç¡®ä¿æ•°æ®åº“å·²åŠ è½½
    global collection
    if collection is None:
        collection = build_collection()
        if collection is None:
            return "ğŸ“­ å½“å‰è¿˜æ²¡æœ‰å¯ç”¨çš„ç¬”è®°ã€‚"

    try:
        # æ£€ç´¢æœ€ç›¸å…³çš„ 3 æ¡ç¬”è®°å†…å®¹
        results = query(collection, query_text, get_embeddings)
        context = "\n\n".join([doc for doc in results[0]])

        # è°ƒç”¨ LLM è¿›è¡Œæ€»ç»“ä¸å›ç­”
        prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸ªäººçŸ¥è¯†åŠ©æ‰‹ã€‚æ ¹æ®ä»¥ä¸‹èµ„æ–™å›ç­”é—®é¢˜ã€‚

é—®é¢˜ï¼š{query_text}
èµ„æ–™ï¼š
{context}

è¯·ç”¨ç®€æ´çš„ä¸­æ–‡æ€»ç»“å›ç­”ã€‚
"""
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}]
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        return f"âŒ æ£€ç´¢æˆ–åˆ†æå‡ºé”™ï¼š{str(e)}"


# === æ„å»º Gradio ç•Œé¢ ===
with gr.Blocks(title="ğŸ§  Personal Knowledge Agent") as demo:
    gr.Markdown("## ğŸ§  Personal Knowledge Agent\nè¾“å…¥ç¬”è®°å³å¯åˆ†ç±»ä¿å­˜ï¼Œä¹Ÿå¯è‡ªç„¶è¯­è¨€æ£€ç´¢åˆ†æã€‚")

    with gr.Tab("âœï¸ æ·»åŠ ç¬”è®°"):
        note_input = gr.Textbox(
            label="è¾“å…¥ç¬”è®°å†…å®¹",
            placeholder="åœ¨è¿™é‡Œè¾“å…¥ä½ çš„ç¬”è®°...",
            lines=8,
        )
        note_output = gr.Markdown(label="è¾“å‡ºç»“æœ")
        submit_btn = gr.Button("ğŸš€ æäº¤ä¿å­˜")
        submit_btn.click(fn=process_note, inputs=note_input, outputs=note_output)

    with gr.Tab("ğŸ“š æŸ¥çœ‹å†å²ç¬”è®°"):
        view_output = gr.Markdown()
        view_btn = gr.Button("ğŸ“– æŸ¥çœ‹å…¨éƒ¨ç¬”è®°")
        view_btn.click(fn=show_notes, outputs=view_output)

    with gr.Tab("ğŸ” æŸ¥è¯¢ç¬”è®°çŸ¥è¯†åº“"):
        query_input = gr.Textbox(
            label="è‡ªç„¶è¯­è¨€æŸ¥è¯¢",
            placeholder="ä¾‹å¦‚ï¼šæ€»ç»“æˆ‘å†™è¿‡çš„å…³äº RAG çš„ç¬”è®°",
            lines=3,
        )
        query_output = gr.Markdown(label="LLM åˆ†æç»“æœ")
        query_btn = gr.Button("ğŸ” æ£€ç´¢å¹¶åˆ†æ")
        query_btn.click(fn=query_notes, inputs=query_input, outputs=query_output)

# === å¯åŠ¨åº”ç”¨ ===
if __name__ == "__main__":
    demo.launch(server_name="0.0.0.0", server_port=7860)
