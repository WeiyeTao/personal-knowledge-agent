import gradio as gr
from pathlib import Path
from openai import OpenAI
import yaml

from tools.file_loader import load_files
from tools.embedder import get_embeddings
from tools.retriever import build_vector_store, query


# === åˆå§‹åŒ– ===
client = OpenAI()
cfg = yaml.safe_load(open("configs/settings.yaml", "r"))
DATA_DIR = Path("data/uploads")
DATA_DIR.mkdir(parents=True, exist_ok=True)


# === å¤„ç†æ–‡ä»¶ä¸Šä¼  ===
def process_files(files):
    """ä¿å­˜ä¸Šä¼ çš„æ–‡ä»¶å¹¶åŠ è½½ä¸ºæ–‡æœ¬"""
    saved_files = []
    for f in files:
        dest = DATA_DIR / Path(f.name).name
        with open(dest, "wb") as out:
            out.write(f.read())
        saved_files.append(str(dest))

    # åŠ è½½æ–‡æœ¬
    docs = load_files([str(DATA_DIR)])
    texts = [d["content"] for d in docs]
    embeddings = get_embeddings(texts)
    collection = build_vector_store(texts, embeddings)
    return "âœ… å·²æˆåŠŸåŠ è½½å¹¶åµŒå…¥æ–‡ä»¶", collection


# === å¤„ç†è‡ªç„¶è¯­è¨€æŒ‡ä»¤ ===
def handle_query(query_text, collection):
    """æ ¹æ®ç”¨æˆ·è‡ªç„¶è¯­è¨€æŒ‡ä»¤æ£€ç´¢ + è°ƒç”¨ LLM"""
    if not query_text.strip():
        return "è¯·è¾“å…¥å†…å®¹ã€‚"

    results = query(collection, query_text, get_embeddings)
    context = "\n\n".join([doc for doc in results[0]])

    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªä¸ªäººçŸ¥è¯†åŠ©æ‰‹ï¼Œè¯·ç»“åˆä»¥ä¸‹å†…å®¹å›ç­”é—®é¢˜ã€‚
å¦‚æœæ–‡ä»¶ä¸­åŒ…å«ä»£ç ï¼Œè¯·è§£é‡Šä»£ç é€»è¾‘ã€‚
å¦‚æœæ˜¯å›¾ç‰‡ï¼Œè¯·æè¿°å®ƒçš„å†…å®¹ã€‚

é—®é¢˜ï¼š{query_text}
ç›¸å…³èµ„æ–™ï¼š
{context}
"""
    response = client.chat.completions.create(
        model=cfg["model"]["llm_model"],
        messages=[{"role": "user", "content": prompt}],
    )
    return response.choices[0].message.content


# === æ„å»º Gradio ç•Œé¢ ===
with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.Markdown("# ğŸ¤– Personal Knowledge Agent")
    gr.Markdown("ä¸Šä¼ æ–‡æ¡£æˆ–è¾“å…¥è‡ªç„¶è¯­è¨€æŒ‡ä»¤ï¼ŒAI å°†å¸®åŠ©ä½ æ•´ç†ã€ç†è§£ä¸ç”Ÿæˆå†…å®¹ã€‚")

    with gr.Row():
        upload = gr.Files(label="ğŸ“‚ ä¸Šä¼ æ–‡ä»¶ï¼ˆä»£ç  / å›¾ç‰‡ / æ–‡æœ¬ï¼‰")
        output_status = gr.Textbox(label="ç³»ç»ŸçŠ¶æ€", interactive=False)

    query_box = gr.Textbox(label="ğŸ’¬ è¾“å…¥ä½ çš„é—®é¢˜ / æŒ‡ä»¤", placeholder="ä¾‹å¦‚ï¼šè¯·è§£é‡Šæˆ‘ä¸Šä¼ çš„ä»£ç é€»è¾‘")
    result_box = gr.Textbox(label="ğŸ§  æ™ºèƒ½å›ç­”", lines=8)

    collection_state = gr.State(None)

    upload.upload(process_files, upload, [output_status, collection_state])
    query_box.submit(handle_query, [query_box, collection_state], result_box)

demo.launch(server_name="0.0.0.0", server_port=7860)
