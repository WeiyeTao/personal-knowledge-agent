from langchain.agents import initialize_agent, AgentType, load_tools
from langchain.llms import Ollama
from langchain.memory import ConversationBufferMemory

llm = Ollama(model="llama3")
memory = ConversationBufferMemory(memory_key="chat_history")

# åŠ è½½ä¸€ä¸ªç®€å•çš„å†…ç½®å·¥å…·
tools = load_tools(["python_repl"], llm=llm)

# åˆå§‹åŒ– Agent
agent = initialize_agent(tools, llm, agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION, memory=memory, verbose=True)

if __name__ == "__main__":
    while True:
        query = input("\nğŸ§  è¾“å…¥ä»»åŠ¡æˆ–é—®é¢˜ (exité€€å‡º): ")
        if query.lower() in ["exit", "quit"]:
            break
        ans = agent.run(query)
        print("\nğŸ¤–:", ans)
