import yaml
from pathlib import Path
from openai import OpenAI
from tools.classifier import classify_text

# åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
client = OpenAI()

def llm_refine_markdown(note_text: str, model="gpt-4o-mini"):
    """è°ƒç”¨ LLM å°†ç¬”è®°å†…å®¹è½¬ä¸º Markdown æ ¼å¼"""
    prompt = f"""
ä½ æ˜¯ä¸€ä¸ªçŸ¥è¯†ç¬”è®°åŠ©æ‰‹ã€‚
è¯·æŠŠä¸‹é¢çš„å†…å®¹æ¶¦è‰²ä¸ºç»“æ„åŒ–çš„ Markdown æ ¼å¼ï¼š
- æ·»åŠ åˆç†çš„æ ‡é¢˜ï¼ˆå¦‚ ## æ¦‚å¿µã€### æ­¥éª¤ç­‰ï¼‰
- ä¿æŒåŸæ„ï¼Œæç‚¼è¦ç‚¹ï¼Œä¼˜åŒ–æ ¼å¼
- ä½¿ç”¨ç®€ä½“ä¸­æ–‡è¾“å‡º

åŸå§‹å†…å®¹ï¼š
{note_text}
    """
    response = client.chat.completions.create(
        model=model,
        messages=[{"role": "user", "content": prompt}],
    )
    return response.choices[0].message.content.strip()


def add_note(note_text: str):
    """è¾“å…¥ç¬”è®° â†’ LLM Markdownæ¶¦è‰² â†’ è‡ªåŠ¨åˆ†ç±» â†’ ä¿å­˜ä¸º.mdæ–‡ä»¶"""
    # 1ï¸âƒ£ è°ƒç”¨ LLM è¿›è¡Œ Markdown æ¶¦è‰²
    refined_md = llm_refine_markdown(note_text)
    print("ğŸª„ å·²é€šè¿‡ LLM ç”Ÿæˆ Markdown æ ¼å¼ç¬”è®°ã€‚")

    # 2ï¸âƒ£ è°ƒç”¨åˆ†ç±»å™¨
    category = classify_text(note_text)
    print(f"[classify] ç¬”è®°åˆ†ç±»ä¸ºï¼š{category}")

    # 3ï¸âƒ£ åˆ›å»ºå¯¹åº”ç±»åˆ«ç›®å½•
    category_dir = Path(f"data/notes/{category}")
    category_dir.mkdir(parents=True, exist_ok=True)

    # 4ï¸âƒ£ ç”Ÿæˆæ–°æ–‡ä»¶åï¼ˆé¿å…è¦†ç›–ï¼‰
    files = list(category_dir.glob("note_*.md"))
    note_id = len(files) + 1
    note_path = category_dir / f"note_{note_id}.md"

    # 5ï¸âƒ£ å†™å…¥ Markdown æ–‡ä»¶
    with open(note_path, "w", encoding="utf-8") as f:
        f.write(f"# åˆ†ç±»ï¼š{category}\n\n")
        f.write(refined_md)

    print(f"[save] âœ… ç¬”è®°å·²ä¿å­˜åˆ°ï¼š{note_path.resolve()}")
    return category, note_path


if __name__ == "__main__":
    print("=== ğŸ§  Personal Knowledge Agent Markdown åˆ†ç±»ç¬”è®° ===")
    note = input("è¯·è¾“å…¥ä¸€æ®µç¬”è®°å†…å®¹ï¼ˆè‡ªåŠ¨åˆ†ç±» + Markdownæ¶¦è‰²ä¿å­˜ï¼‰:\n> ")

    if not note.strip():
        print("âš ï¸ è¾“å…¥ä¸ºç©ºï¼Œå·²é€€å‡ºã€‚")
    else:
        add_note(note)
